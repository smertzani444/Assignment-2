{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b76a15a",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ddb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.base import clone\n",
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0460971",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "        if not os.path.isfile(path):\n",
    "            raise FileNotFoundError(f\"The file at {path} was not found.\")\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "path_to_data=\"/home/user_stel/Assignment-2/data/breast_cancer.csv\"\n",
    "data_df=load_data(path_to_data)\n",
    "\n",
    "#print(data_df.head()) #it should display a 512x32 dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994be606",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, columns_to_drop=[]):\n",
    "    df=df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    num_list=df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_list=df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    for col in cat_list:\n",
    "        df[col]=LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    for col in num_list:\n",
    "        df[col]=SimpleImputer(missing_values=np.nan, strategy='mean') \\\n",
    "            .fit_transform(df[[col]]).ravel()\n",
    "    \n",
    "    return df\n",
    "\n",
    "data_new_df=preprocess_data(data_df, columns_to_drop=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b601ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_target(df, target, columns_to_remove=None):\n",
    "    if columns_to_remove is None:\n",
    "        columns_to_remove=[]\n",
    "    columns_to_remove=set(columns_to_remove + [target])\n",
    "    X=df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "    y=df[target]\n",
    "    return X, y\n",
    "\n",
    "X, y=separate_features_target(data_new_df, target='diagnosis', columns_to_remove=None)\n",
    "#print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41381290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, threshold=0.1):\n",
    "    correlations = pd.Series(r_regression(X, y), index=X.columns)\n",
    "    selected_features = correlations[correlations.abs() >= threshold].index.tolist()\n",
    "    print(f\"The selected features of {X.shape[1]} were: {len(selected_features)}\")\n",
    "    return selected_features, correlations\n",
    "\n",
    "selected_features, correlations=select_features(X, y, threshold=0.5)\n",
    "print(selected_features)\n",
    "\n",
    "# Creates a new dataset that contains only the selected features \n",
    "X_selected=X[selected_features]\n",
    "#print(X_selected)\n",
    "\n",
    "selected_feature_names = X_selected.columns.tolist()\n",
    "target = 'diagnosis'\n",
    "data_selected_df = data_new_df[selected_feature_names + [target]]\n",
    "#print(data_selected_df) # the way this new dataframe is built the diagnosis column is last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17c9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression-elasticnet': LogisticRegression(\n",
    "        penalty='elasticnet', solver='saga', random_state=0, max_iter=10000\n",
    "    ),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(random_state=0),\n",
    "    'RandomForest': RandomForestClassifier(random_state=0),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'LogisticRegression-elasticnet': {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'l1_ratio': [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'var_smoothing': np.logspace(-9, -1, 9)\n",
    "    },\n",
    "    'LDA': [\n",
    "        {'solver': ['svd']},\n",
    "        {'solver': ['lsqr', 'eigen'], 'shrinkage': [None, 'auto']}\n",
    "    ],\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.01, 0.1]}\n",
    "    ],\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [-1, 10, 20]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly modified generate_param_combinations function from previous assignment because for this project the param_grid conains lists of dictionaries \n",
    "# for two separet models \n",
    "def generate_param_combintions(param_grid):\n",
    "    model_combinations = {}\n",
    "    for model, params in param_grid.items():\n",
    "        \n",
    "        if isinstance(params, list):\n",
    "            param_combinations = []\n",
    "            for param_set in params:\n",
    "                param_combinations.extend(\n",
    "                    [dict(zip(param_set.keys(), values)) for values in itertools.product(*param_set.values())]\n",
    "                )\n",
    "            model_combinations[model] = param_combinations\n",
    "        else:\n",
    "            model_combinations[model] = [\n",
    "                dict(zip(params.keys(), values)) for values in itertools.product(*params.values())\n",
    "            ]\n",
    "    return model_combinations\n",
    "\n",
    "model_combinations=generate_param_combintions(param_grid)\n",
    "model_combo_df_summary = pd.DataFrame.from_dict(model_combinations, orient='index')\n",
    "#print(model_combo_df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y=separate_features_target(data_selected_df, target='diagnosis', columns_to_remove=None)\n",
    "#print(X)\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e987397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncv_model(df, models, param_grid, n_rounds, outer_cv, inner_cv, columns_to_remove=[]):\n",
    "    X, y=separate_features_target(df, target='diagnosis', columns_to_remove=columns_to_remove)\n",
    "\n",
    "    all_f1_scores = []\n",
    "    \n",
    "    for i in range(n_rounds):\n",
    "        X_train, x_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        X.columns = X.columns.str.replace(' ', '_')\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            model_param_grid=param_grid[model_name]\n",
    "\n",
    "            gs = GridSearchCV(estimator=model, param_grid=model_param_grid,\n",
    "                     cv=inner_cv, scoring='accuracy', n_jobs=1, refit=True)\n",
    "            \n",
    "            scaler=StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "            gs.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "            # Get the best model after hyperparameter tuning\n",
    "            best_model = gs.best_estimator_\n",
    "\n",
    "            # Use the best model to make predictions on the outer test set\n",
    "            x_test_scaled = scaler.transform(x_test)  # Scale the outer test set with the same scaler\n",
    "            x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=X_train.columns)\n",
    "            y_pred = best_model.predict(x_test_scaled_df)\n",
    "\n",
    "            # Calculate the F1 score on the outer test set\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            all_f1_scores.append(f1)\n",
    "            \n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Outer Test Set F1 Score: {f1:.3f}\")\n",
    "            print('-' * 50)\n",
    "    \n",
    "    return all_f1_scores\n",
    "    \n",
    "results=ncv_model(data_selected_df, models=models, param_grid=param_grid, n_rounds=10, outer_cv=5, inner_cv=3, columns_to_remove=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
